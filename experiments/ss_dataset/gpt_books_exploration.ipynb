{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import functional as F\n",
    "\n",
    "batch_size = 32\n",
    "block_size = 5\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(PROJECT_ROOT, \"data\")\n",
    "PATH_RATINGS = os.path.join(DATA_PATH, \"raw_data\", \"kaggle_second_sem\", \"books_rating.csv\")\n",
    "PATH_BOOKS = os.path.join(DATA_PATH, \"raw_data\", \"kaggle_second_sem\", \"books_data.csv\")\n",
    "PATH_EMBDS = os.path.join(DATA_PATH, \"embeddings\", \"expanded_embds_ss.npy\")\n",
    "\n",
    "df_books = pd.read_csv(PATH_BOOKS)\n",
    "df_ratings = pd.read_csv(PATH_RATINGS)\n",
    "book_embds = np.load(PATH_EMBDS, allow_pickle=True)\n",
    "\n",
    "# Book embds has shape like\n",
    "#(Title, (author, 1), (categories, 1), (publisher, 1), (description_embd, 384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_seqs = df_ratings.groupby(\"User_id\")[\"Title\"].apply(lambda x: list(set(x.tolist()))).loc[lambda x: x.str.len() > 5].reset_index()\n",
    "train = ratings_seqs[\"Title\"].iloc[:30000]\n",
    "test = ratings_seqs[\"Title\"].iloc[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(2, (3, 3))\n",
    "\n",
    "# torch.randint(len(train[1636]) - block_size, (1,))\n",
    "torch.randint(len(train[20551]) - block_size, (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_embds_dict = {row[0]: np.array(row[1:], dtype=np.float32) for row in book_embds}\n",
    "\n",
    "def encode(book_title):\n",
    "    return book_embds_dict[book_title]\n",
    "def encode_seq(seq):\n",
    "    return [book_embds_dict[title] for title in seq]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_seq(seq):\n",
    "    for title in seq:\n",
    "        print(title)\n",
    "    return [book_embds_dict[title] for title in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    data = train if split == 'train' else test\n",
    "    ix = torch.randint(len(train), (batch_size,))\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in ix:\n",
    "        i = int(i)       \n",
    "        j = torch.randint(len(data[i]) - block_size, (1,))\n",
    "        x.append(encode_seq(data[i][j:j + block_size]))\n",
    "        y.append(encode_seq(data[i][j + 1:j + block_size + 1]))\n",
    "\n",
    "    x = torch.tensor(x)\n",
    "    y = torch.tensor(y)\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ivans\\AppData\\Local\\Temp\\ipykernel_10036\\2990964281.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  x = torch.tensor(x)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[166], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[165], line 15\u001b[0m, in \u001b[0;36mget_batch\u001b[1;34m(split)\u001b[0m\n\u001b[0;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x)\n\u001b[0;32m     14\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y)\n\u001b[1;32m---> 15\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(y)\n\u001b[0;32m     17\u001b[0m x, y \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device), y\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mTypeError\u001b[0m: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor"
     ]
    }
   ],
   "source": [
    "get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.00000000e+00,  3.00000000e+00,  5.53010000e+04,  5.39400000e+03,\n",
       "        5.97800000e+03, -3.26101761e-03, -3.80467623e-02, -2.20663417e-02,\n",
       "       -2.06969202e-01, -1.53353333e-01, -3.34080428e-01,  1.87948778e-01,\n",
       "        1.97183177e-01,  6.31333515e-02, -6.38172477e-02,  3.18448842e-01,\n",
       "       -1.28581487e-02,  2.54372358e-01,  7.15852305e-02, -4.01395649e-01,\n",
       "       -2.41744950e-01, -2.24365532e-01, -2.47502491e-01, -7.54199922e-02,\n",
       "        4.36054915e-01, -1.83131129e-01,  6.35326281e-03,  4.76917207e-01,\n",
       "        9.54845473e-02, -2.86872275e-02, -4.59304899e-01,  2.59732425e-01,\n",
       "        3.26311812e-02, -2.70776570e-01,  6.10380173e-02, -5.23494324e-04,\n",
       "        6.88992143e-02, -1.18377611e-01, -1.30543888e-01,  1.31465495e-01,\n",
       "        1.58350468e-01, -4.59487131e-03, -3.90655249e-02, -6.79950044e-02,\n",
       "        7.54482672e-02,  1.24994785e-01, -3.03720534e-01,  7.06110001e-02,\n",
       "        1.67423427e-01, -2.14514136e-01,  4.95938510e-02, -3.52938883e-02,\n",
       "       -2.03758657e-01,  1.64513096e-01, -1.07030049e-01, -1.49708495e-01,\n",
       "        2.47890323e-01,  1.62435144e-01, -4.59976345e-01,  1.52609944e-01,\n",
       "       -1.80632453e-02,  1.24950195e-02,  4.45592999e-01,  3.17953378e-01,\n",
       "        1.71134502e-01,  2.19585627e-01,  5.34498453e-01, -1.12287767e-01,\n",
       "        1.34900108e-01,  1.11015946e-01, -2.80408077e-02,  1.25302076e-01,\n",
       "       -1.59809649e-01, -4.76267755e-01,  1.91379368e-01,  4.95098352e-01,\n",
       "       -3.13755780e-01,  2.42887624e-02,  2.20035225e-01, -4.03151661e-01,\n",
       "        6.46133348e-02, -1.87105060e-01, -1.56406417e-01, -1.21505737e-01,\n",
       "       -2.56476179e-02, -3.84638786e-01,  3.75502408e-02, -1.51451364e-01,\n",
       "        2.00037528e-02,  3.20166588e-01,  3.73356193e-02, -1.97114885e-01,\n",
       "       -3.29496324e-01, -7.43778050e-02,  1.96386039e-01,  5.03206477e-02,\n",
       "        1.00480556e-01,  3.72468054e-01,  1.14286385e-01,  2.08240762e-01,\n",
       "        1.58405840e-01,  1.68107629e-01,  2.33256482e-02, -9.85651851e-01,\n",
       "        6.12609535e-02,  2.01762002e-02,  1.97279647e-01, -1.46962255e-01,\n",
       "        1.93566918e-01,  1.53322648e-02,  3.07344675e-01,  1.42576605e-01,\n",
       "       -4.20503736e-01, -3.22000086e-01,  7.07683489e-02,  2.78597977e-02,\n",
       "       -1.41222224e-01, -1.70679986e-01,  1.58804536e-01,  3.39435935e-01,\n",
       "       -5.09169400e-02, -7.74201900e-02,  1.10365339e-02, -4.02179919e-02,\n",
       "        9.62802619e-02,  9.73183066e-02,  4.05159563e-01, -2.40274206e-01,\n",
       "        2.29432657e-01,  1.91781372e-01, -3.01462501e-01, -7.81774670e-02,\n",
       "        1.84466869e-01, -2.11527705e-01,  1.59486756e-01, -3.21915329e-01,\n",
       "        1.66289181e-01, -2.64917523e-01,  1.83893546e-01, -2.70001978e-01,\n",
       "       -4.10140827e-02,  4.77853864e-02,  2.68060088e-01, -1.42863691e-01,\n",
       "        2.72335798e-01,  8.61778036e-02, -1.95778340e-01, -2.05168843e-01,\n",
       "        6.76006898e-02,  2.35993080e-02, -7.45596588e-02,  4.13197652e-02,\n",
       "       -1.06472328e-01,  2.08290480e-02,  4.27955747e-01,  1.34962976e-01,\n",
       "       -2.06258148e-01,  9.54998285e-03, -3.10695410e-01, -2.56638348e-01,\n",
       "       -2.76728600e-01,  1.80835068e-01,  3.51409376e-01, -2.12445945e-01,\n",
       "        2.21989185e-01,  2.66277194e-01,  1.06060013e-01,  2.13111453e-02,\n",
       "        1.16573095e-01, -2.75174379e-01, -1.67798206e-01, -2.21965969e-01,\n",
       "        2.98026472e-01, -3.50095451e-01, -1.92756847e-01, -2.13809490e-01,\n",
       "        1.20628186e-01, -3.65284175e-01,  2.95043737e-03,  2.21333623e-01,\n",
       "       -3.67534012e-01, -2.77589411e-01,  6.05740398e-02,  5.65605052e-02,\n",
       "       -9.66428518e-02, -2.88021594e-01,  1.31140560e-01, -1.75568491e-01,\n",
       "       -1.34755507e-01, -9.26647335e-02,  6.42007440e-02, -6.24536797e-02,\n",
       "       -9.19734538e-02, -1.29996791e-01,  1.38350591e-01,  1.30288869e-01,\n",
       "       -6.26348332e-02,  2.63171643e-03, -2.12785572e-01, -1.49006963e-01,\n",
       "        1.57801211e-02,  3.43463644e-02, -2.49491543e-01,  9.64980125e-02,\n",
       "        2.99196839e-02, -1.71384618e-01,  6.32889867e-02,  1.70680612e-01,\n",
       "       -3.60199153e-01, -4.47698683e-03, -1.89488068e-01, -1.25123322e-01,\n",
       "       -2.44072512e-01, -1.16796806e-01,  4.14241016e-01,  8.34874958e-02,\n",
       "        1.72004759e-01,  1.40483916e-01, -4.26578000e-02,  1.69078842e-01,\n",
       "        1.15376428e-01,  2.06524469e-02,  5.71048558e-01,  4.72761691e-01,\n",
       "       -4.41412404e-02,  1.39251903e-01, -2.60629077e-02,  3.57287556e-01,\n",
       "       -2.13107914e-01,  1.97797924e-01,  1.48831904e-02,  2.89453864e-01,\n",
       "       -1.69392467e-01, -1.70840397e-01, -2.85299331e-01, -6.93638027e-02,\n",
       "       -2.25057811e-01,  2.33415008e-01,  7.74113536e-02, -5.99488735e-01,\n",
       "        1.58215612e-02,  2.19203860e-01, -1.28365219e-01,  4.62108701e-01,\n",
       "       -2.22115964e-01, -2.41363626e-02,  7.86536932e-02,  3.30888987e-01,\n",
       "        8.37770998e-02,  2.64904052e-01,  1.45583451e-01, -2.52615243e-01,\n",
       "        8.31990391e-02, -7.26069659e-02,  5.54963909e-02, -3.72365534e-01,\n",
       "        2.96532094e-01, -6.58026412e-02,  7.78237879e-02, -2.38534033e-01,\n",
       "        7.63965547e-02,  1.40232384e-01, -2.17896536e-01,  1.08496256e-01,\n",
       "        1.73672855e-01, -1.43688738e-01,  3.59990418e-01, -1.25974119e-01,\n",
       "       -1.00012213e-01,  1.05179280e-01, -4.59137291e-01, -1.65261224e-01,\n",
       "       -8.51964019e-03,  3.69561911e-02,  1.54034123e-01,  4.76214260e-01,\n",
       "       -2.66311109e-01,  4.11709517e-01, -3.69015694e-01,  4.24052924e-01,\n",
       "        5.99737048e-01,  1.77344561e-01,  2.27151498e-01, -2.12775007e-01,\n",
       "        3.81051242e-01, -1.25811726e-01,  3.42438146e-02,  1.34182304e-01,\n",
       "        1.72279164e-01,  2.51316756e-01, -1.26547486e-01, -2.66711205e-01,\n",
       "       -2.32209787e-02, -1.34573475e-01,  9.39151049e-02, -2.58685201e-01,\n",
       "       -2.02442735e-01, -1.42363176e-01, -1.20869271e-01, -1.97705358e-01,\n",
       "       -3.52942526e-01, -2.32473135e-01, -2.72999704e-01,  1.49436355e-01,\n",
       "        3.23180735e-01,  3.03321984e-02, -1.31471395e-01,  2.21058905e-01,\n",
       "       -1.85377628e-01,  6.15667887e-02,  2.36143470e-02, -1.29088849e-01,\n",
       "       -1.54404312e-01, -2.29589082e-03, -2.31054872e-01,  4.65882897e-01,\n",
       "       -1.44164264e-01,  1.11880809e-01,  3.80116433e-01,  4.10580993e-01,\n",
       "       -1.41097419e-03,  7.34172165e-02, -7.24685639e-02,  2.27210596e-01,\n",
       "        9.39622074e-02,  5.29082082e-02,  1.98932111e-01, -2.75501579e-01,\n",
       "        2.06185997e-01,  3.69362354e-01, -4.03646007e-02, -3.62149328e-02,\n",
       "       -3.53264123e-01, -2.05407083e-01,  5.42921126e-01,  2.24960119e-01,\n",
       "        2.00180352e-01, -2.26386011e-01,  3.33188213e-02,  1.19001418e-01,\n",
       "        3.56567144e-01,  6.50953948e-02, -2.75643468e-01, -2.65714407e-01,\n",
       "        2.01619327e-01,  9.19341072e-02, -2.82465696e-01, -7.94119090e-02,\n",
       "       -3.19172502e-01, -3.29954147e-01,  1.83972847e-02,  1.63821846e-01,\n",
       "        2.76943773e-01,  6.11938071e-03,  2.69205868e-01,  5.13728447e-02,\n",
       "       -4.47790846e-02, -3.93219769e-01,  7.77984560e-02, -1.77669466e-01,\n",
       "        1.55005738e-01, -2.25051567e-01,  1.91478997e-01, -4.16759849e-02,\n",
       "       -2.56500244e-01, -2.34609753e-01,  1.01490028e-01, -3.79138112e-01,\n",
       "        2.42343217e-01, -3.62260193e-02,  1.68734223e-01,  1.24142751e-01,\n",
       "        1.33581813e-02, -1.09764293e-01, -9.59075466e-02,  2.83674803e-03,\n",
       "       -1.06033511e-01,  4.81588840e-02, -7.00947642e-02,  3.43755811e-01,\n",
       "       -1.94117054e-01,  3.11287284e-01,  7.91647881e-02, -6.08523250e-01,\n",
       "        2.04241812e-01, -2.36770958e-01, -3.12053449e-02,  1.95743382e-01,\n",
       "       -1.49837628e-01], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_embds_dict[\"Open Secret: Lost... But Not Forgotten (Harlequin Superromance No 1332)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimus(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.author_embds = nn.Embedding(1, 20)\n",
    "        self.cat_embds = nn.Embedding(1, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (books)",
   "language": "python",
   "name": "books"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
